{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36ee0b3",
   "metadata": {},
   "source": [
    "1:16 \n",
    "[Link](https://www.linkedin.com/learning/nlp-with-python-for-machine-learning-essential-training/implementation-removing-punctuation?u=74412268)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bace280",
   "metadata": {},
   "source": [
    "Steps to NLP for ML:\n",
    "\n",
    "1) Raw text - mdoel cannot read text\n",
    "\n",
    "2) Tokenizing - telling model what to read from file \n",
    "\n",
    "3) Clean text - remove stop words, punctuation, stemming, etc.\n",
    "\n",
    "4) Vectorize - turn data to numeric form\n",
    "\n",
    "5) Machine Learning - put into model for train/test\n",
    "    - classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50544059",
   "metadata": {},
   "source": [
    "## 1) Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903e3db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive/Negative rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I think food should have flavor and texture and both were lacking.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Overall I was not impressed and would not go back.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Review  \\\n",
       "996                                    I think food should have flavor and texture and both were lacking.   \n",
       "997                                                                              Appetite instantly gone.   \n",
       "998                                                    Overall I was not impressed and would not go back.   \n",
       "999           The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.   \n",
       "1000  Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing ou...   \n",
       "\n",
       "     Positive/Negative rating  \n",
       "996                         0  \n",
       "997                         0  \n",
       "998                         0  \n",
       "999                         0  \n",
       "1000                        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 100) #set layout table\n",
    "\n",
    "my_data = pd.read_csv(\"Restaurant_Reviews.tsv\", sep=\"\\t\", header=None)\n",
    "my_data.columns = [\"Review\",\"Positive/Negative rating\"]\n",
    "\n",
    "my_data[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf9a90",
   "metadata": {},
   "source": [
    "## 2) Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efad9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c58d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    # Use regular expression to remove punctuation and replace with a space\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e0e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'Message' column and create a new column 'Cleaned_Message'\n",
    "my_data['Cleaned_Review'] = my_data['Review'].apply(remove_punctuation)\n",
    "\n",
    "# Save the cleaned data to a new TSV file\n",
    "my_data.to_csv('my_datacleaned_file.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d792ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive/Negative rating</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I think food should have flavor and texture and both were lacking.</td>\n",
       "      <td>0</td>\n",
       "      <td>I think food should have flavor and texture and both were lacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>Appetite instantly gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Overall I was not impressed and would not go back.</td>\n",
       "      <td>0</td>\n",
       "      <td>Overall I was not impressed and would not go back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.</td>\n",
       "      <td>0</td>\n",
       "      <td>The whole experience was underwhelming  and I think we ll just go to Ninja Sushi next time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Then  as if I hadn t wasted enough of my life there  they poured salt in the wound by drawing ou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Review  \\\n",
       "996                                    I think food should have flavor and texture and both were lacking.   \n",
       "997                                                                              Appetite instantly gone.   \n",
       "998                                                    Overall I was not impressed and would not go back.   \n",
       "999           The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.   \n",
       "1000  Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing ou...   \n",
       "\n",
       "     Positive/Negative rating  \\\n",
       "996                         0   \n",
       "997                         0   \n",
       "998                         0   \n",
       "999                         0   \n",
       "1000                        0   \n",
       "\n",
       "                                                                                           Cleaned_Review  \n",
       "996                                    I think food should have flavor and texture and both were lacking   \n",
       "997                                                                              Appetite instantly gone   \n",
       "998                                                    Overall I was not impressed and would not go back   \n",
       "999           The whole experience was underwhelming  and I think we ll just go to Ninja Sushi next time   \n",
       "1000  Then  as if I hadn t wasted enough of my life there  they poured salt in the wound by drawing ou...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clean_data = pd.read_csv(\"my_datacleaned_file.tsv\", sep=\"\\t\")\n",
    "\n",
    "my_clean_data[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307f381",
   "metadata": {},
   "source": [
    "## 3) Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1707f6",
   "metadata": {},
   "source": [
    "Chops up words in the cleaned_review column. Good for adding vocabulary to model's bank and preprocessing of smaller managable pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9feddded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive/Negative rating</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I think food should have flavor and texture and both were lacking.</td>\n",
       "      <td>0</td>\n",
       "      <td>I think food should have flavor and texture and both were lacking</td>\n",
       "      <td>[i, think, food, should, have, flavor, and, texture, and, both, were, lacking, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>Appetite instantly gone</td>\n",
       "      <td>[appetite, instantly, gone, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Overall I was not impressed and would not go back.</td>\n",
       "      <td>0</td>\n",
       "      <td>Overall I was not impressed and would not go back</td>\n",
       "      <td>[overall, i, was, not, impressed, and, would, not, go, back, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.</td>\n",
       "      <td>0</td>\n",
       "      <td>The whole experience was underwhelming  and I think we ll just go to Ninja Sushi next time</td>\n",
       "      <td>[the, whole, experience, was, underwhelming, and, i, think, we, ll, just, go, to, ninja, sushi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Then  as if I hadn t wasted enough of my life there  they poured salt in the wound by drawing ou...</td>\n",
       "      <td>[then, as, if, i, hadn, t, wasted, enough, of, my, life, there, they, poured, salt, in, the, wou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Review  \\\n",
       "996                                    I think food should have flavor and texture and both were lacking.   \n",
       "997                                                                              Appetite instantly gone.   \n",
       "998                                                    Overall I was not impressed and would not go back.   \n",
       "999           The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.   \n",
       "1000  Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing ou...   \n",
       "\n",
       "     Positive/Negative rating  \\\n",
       "996                         0   \n",
       "997                         0   \n",
       "998                         0   \n",
       "999                         0   \n",
       "1000                        0   \n",
       "\n",
       "                                                                                           Cleaned_Review  \\\n",
       "996                                    I think food should have flavor and texture and both were lacking    \n",
       "997                                                                              Appetite instantly gone    \n",
       "998                                                    Overall I was not impressed and would not go back    \n",
       "999           The whole experience was underwhelming  and I think we ll just go to Ninja Sushi next time    \n",
       "1000  Then  as if I hadn t wasted enough of my life there  they poured salt in the wound by drawing ou...   \n",
       "\n",
       "                                                                                                Tokenized  \n",
       "996                      [i, think, food, should, have, flavor, and, texture, and, both, were, lacking, ]  \n",
       "997                                                                         [appetite, instantly, gone, ]  \n",
       "998                                        [overall, i, was, not, impressed, and, would, not, go, back, ]  \n",
       "999   [the, whole, experience, was, underwhelming, and, i, think, we, ll, just, go, to, ninja, sushi, ...  \n",
       "1000  [then, as, if, i, hadn, t, wasted, enough, of, my, life, there, they, poured, salt, in, the, wou...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses re\n",
    "\n",
    "def data_tokenization(text):\n",
    "    #for every word in review\n",
    "    \n",
    "    #split word\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    return tokens\n",
    "    #tokenized = original.tokenizeFunct column\n",
    "my_data['Tokenized'] = my_data['Cleaned_Review'].apply(lambda x:data_tokenization(x.lower()))\n",
    "\n",
    "my_data[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097dfcd2",
   "metadata": {},
   "source": [
    "## Test case sensitivity NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babcb64f",
   "metadata": {},
   "source": [
    "Purpose of using .lower method is to turn all capital letters to lower case so it knows the words are the same thing. \n",
    "\n",
    "To us, SONIC is the same as sonic, but since Python is case senitive, it see the two words as different things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36e0be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"SONIC\" == \"sonic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0717c4a",
   "metadata": {},
   "source": [
    "## 4) Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b679ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15297261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive/Negative rating</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Remove_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I think food should have flavor and texture and both were lacking.</td>\n",
       "      <td>0</td>\n",
       "      <td>I think food should have flavor and texture and both were lacking</td>\n",
       "      <td>[i, think, food, should, have, flavor, and, texture, and, both, were, lacking, ]</td>\n",
       "      <td>{flavor, , texture, think, food, lacking}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>Appetite instantly gone</td>\n",
       "      <td>[appetite, instantly, gone, ]</td>\n",
       "      <td>{, appetite, instantly, gone}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Overall I was not impressed and would not go back.</td>\n",
       "      <td>0</td>\n",
       "      <td>Overall I was not impressed and would not go back</td>\n",
       "      <td>[overall, i, was, not, impressed, and, would, not, go, back, ]</td>\n",
       "      <td>{, impressed, go, back, overall, would}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.</td>\n",
       "      <td>0</td>\n",
       "      <td>The whole experience was underwhelming  and I think we ll just go to Ninja Sushi next time</td>\n",
       "      <td>[the, whole, experience, was, underwhelming, and, i, think, we, ll, just, go, to, ninja, sushi, ...</td>\n",
       "      <td>{, go, underwhelming, think, whole, ninja, next, time, sushi, experience}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Then  as if I hadn t wasted enough of my life there  they poured salt in the wound by drawing ou...</td>\n",
       "      <td>[then, as, if, i, hadn, t, wasted, enough, of, my, life, there, they, poured, salt, in, the, wou...</td>\n",
       "      <td>{, check, took, bring, wasted, enough, life, drawing, time, poured, salt, wound}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Review  \\\n",
       "996                                    I think food should have flavor and texture and both were lacking.   \n",
       "997                                                                              Appetite instantly gone.   \n",
       "998                                                    Overall I was not impressed and would not go back.   \n",
       "999           The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.   \n",
       "1000  Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing ou...   \n",
       "\n",
       "     Positive/Negative rating  \\\n",
       "996                         0   \n",
       "997                         0   \n",
       "998                         0   \n",
       "999                         0   \n",
       "1000                        0   \n",
       "\n",
       "                                                                                           Cleaned_Review  \\\n",
       "996                                    I think food should have flavor and texture and both were lacking    \n",
       "997                                                                              Appetite instantly gone    \n",
       "998                                                    Overall I was not impressed and would not go back    \n",
       "999           The whole experience was underwhelming  and I think we ll just go to Ninja Sushi next time    \n",
       "1000  Then  as if I hadn t wasted enough of my life there  they poured salt in the wound by drawing ou...   \n",
       "\n",
       "                                                                                                Tokenized  \\\n",
       "996                      [i, think, food, should, have, flavor, and, texture, and, both, were, lacking, ]   \n",
       "997                                                                         [appetite, instantly, gone, ]   \n",
       "998                                        [overall, i, was, not, impressed, and, would, not, go, back, ]   \n",
       "999   [the, whole, experience, was, underwhelming, and, i, think, we, ll, just, go, to, ninja, sushi, ...   \n",
       "1000  [then, as, if, i, hadn, t, wasted, enough, of, my, life, there, they, poured, salt, in, the, wou...   \n",
       "\n",
       "                                                                           Remove_stop  \n",
       "996                                          {flavor, , texture, think, food, lacking}  \n",
       "997                                                      {, appetite, instantly, gone}  \n",
       "998                                            {, impressed, go, back, overall, would}  \n",
       "999          {, go, underwhelming, think, whole, ninja, next, time, sushi, experience}  \n",
       "1000  {, check, took, bring, wasted, enough, life, drawing, time, poured, salt, wound}  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    my_text = {word for word in tokenized_list if word not in stopword}\n",
    "    return my_text\n",
    "\n",
    "my_data['Remove_stop'] = my_data['Tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "my_data[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f638488",
   "metadata": {},
   "source": [
    "## 5) Split into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc744867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use punctuation removed text,  review, and tokenized version to test if model can properly categorize each review\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(my_data[[\"Cleaned_Review\",\"Tokenized\",\"Remove_stop\"]], my_data[\"Positive/Negative rating\"], test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820080f3",
   "metadata": {},
   "source": [
    "## 6) Vectorize data\n",
    "\n",
    "Turn the text into numerical points for the model to easily use for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce79422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2262d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Remove_stop</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>[the, one, down, note, is, the, ventilation, could, use, some, upgrading, ]</td>\n",
       "      <td>{, use, note, could, ventilation, upgrading, one}</td>\n",
       "      <td>0.645829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083539</td>\n",
       "      <td>0.065972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>[the, food, is, delicious, and, just, spicy, enough, so, be, sure, to, ask, for, spicier, if, yo...</td>\n",
       "      <td>{, spicier, spicy, enough, way, food, ask, prefer, delicious, sure}</td>\n",
       "      <td>0.531308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.264312</td>\n",
       "      <td>0.061375</td>\n",
       "      <td>0.296050</td>\n",
       "      <td>0.116897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[that, s, right, the, red, velvet, cake, ohhh, this, stuff, is, so, good, ]</td>\n",
       "      <td>{, stuff, red, velvet, cake, ohhh, good, right}</td>\n",
       "      <td>0.610909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261323</td>\n",
       "      <td>0.303911</td>\n",
       "      <td>0.211710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>[there, is, nothing, privileged, about, working, eating, there, ]</td>\n",
       "      <td>{, privileged, nothing, eating, working}</td>\n",
       "      <td>0.602391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078820</td>\n",
       "      <td>0.152775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192510</td>\n",
       "      <td>0.101351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>[cant, say, enough, good, things, about, this, place, ]</td>\n",
       "      <td>{, cant, enough, things, say, place, good}</td>\n",
       "      <td>0.434030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160907</td>\n",
       "      <td>0.311883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               Tokenized  \\\n",
       "472                          [the, one, down, note, is, the, ventilation, could, use, some, upgrading, ]   \n",
       "449  [the, food, is, delicious, and, just, spicy, enough, so, be, sure, to, ask, for, spicier, if, yo...   \n",
       "26                           [that, s, right, the, red, velvet, cake, ohhh, this, stuff, is, so, good, ]   \n",
       "252                                    [there, is, nothing, privileged, about, working, eating, there, ]   \n",
       "503                                              [cant, say, enough, good, things, about, this, place, ]   \n",
       "\n",
       "                                                             Remove_stop  \\\n",
       "472                    {, use, note, could, ventilation, upgrading, one}   \n",
       "449  {, spicier, spicy, enough, way, food, ask, prefer, delicious, sure}   \n",
       "26                       {, stuff, red, velvet, cake, ohhh, good, right}   \n",
       "252                             {, privileged, nothing, eating, working}   \n",
       "503                           {, cant, enough, things, say, place, good}   \n",
       "\n",
       "            0    1    2    3    4    5    6    7  ...        55        56  \\\n",
       "472  0.645829  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000  0.149167   \n",
       "449  0.531308  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.227273  0.264312   \n",
       "26   0.610909  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.261323  0.303911   \n",
       "252  0.602391  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.078820  0.152775   \n",
       "503  0.434030  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.160907  0.311883   \n",
       "\n",
       "           57        58        59   60        61   62   63   64  \n",
       "472  0.000000  0.083539  0.065972  0.0  0.069849  0.0  0.0  0.0  \n",
       "449  0.061375  0.296050  0.116897  0.0  0.061883  0.0  0.0  0.0  \n",
       "26   0.211710  0.000000  0.000000  0.0  0.213465  0.0  0.0  0.0  \n",
       "252  0.000000  0.192510  0.101351  0.0  0.053654  0.0  0.0  0.0  \n",
       "503  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vector = TfidfVectorizer(analyzer=remove_punctuation) #  'char', 'char_wb', 'word', or a callable function.\n",
    "data_vector_fit = data_vector.fit(X_train[\"Cleaned_Review\"])\n",
    "\n",
    "## error on parameters\n",
    "\n",
    "#fixed by putting function of text with removed punctuation into analyzer - 9/12\n",
    "\n",
    "data_train = data_vector_fit.transform(X_train[\"Cleaned_Review\"])\n",
    "data_test = data_vector_fit.transform(X_test[\"Cleaned_Review\"])\n",
    "\n",
    "#accepts list of object - connect data based on indicies \n",
    "#turn matrix to dataframe\n",
    "#put data in dataframe side by side\n",
    "X_train_vect = pd.concat([X_train[[\"Tokenized\",\"Remove_stop\"]], \n",
    "           pd.DataFrame(data_train.toarray())], axis=1)\n",
    "\n",
    "X_test_vect = pd.concat([X_test[[\"Tokenized\",\"Remove_stop\"]], \n",
    "           pd.DataFrame(data_test.toarray())], axis=1)\n",
    "\n",
    "X_train_vect.head()\n",
    "\n",
    "#some words are not recogized to be vectorized which is ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae4688",
   "metadata": {},
   "source": [
    "## 7) Final Evaluation of Model\n",
    "\n",
    "Use a classification model- Random Forrest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import time\n",
    "#checkpoint: https://www.linkedin.com/learning/nlp-with-python-for-machine-learning-essential-training/model-selection-data-prep?u=74412268\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
